name: ML Pipeline

on:
  push:
    branches: [ main ]
  workflow_dispatch:

jobs:
  train-and-validate:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:13
        env:
          POSTGRES_USER: airflow
          POSTGRES_PASSWORD: airflow
          POSTGRES_DB: airflow
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.9'

      - name: Install Docker Compose
        run: |
          python -m pip install --upgrade pip
          pip install docker-compose

      - name: Setup Credentials
        run: |
          mkdir -p credentials
          echo '${{ secrets.GOOGLE_APPLICATION_CREDENTIALS }}' > credentials/latest.json
          chmod 600 credentials/latest.json

      - name: Create Docker network
        run: docker network create airflow-network

      - name: Create Airflow directories with proper permissions
        run: |
          mkdir -p ./logs ./plugins ./data
          chmod -R 777 ./logs ./plugins ./data

      - name: Build Airflow Image
        run: |
          docker build -t airflow_custom -f docker/airflow/Dockerfile .

      - name: Start Postgres
        run: |
          docker run -d \
            --name postgres \
            --network airflow-network \
            -e POSTGRES_USER=airflow \
            -e POSTGRES_PASSWORD=airflow \
            -e POSTGRES_DB=airflow \
            postgres:13

      - name: Start Airflow
        run: |
          docker run -d \
            --name airflow \
            --network airflow-network \
            -e AIRFLOW__CORE__SQL_ALCHEMY_CONN="postgresql+psycopg2://airflow:airflow@postgres/airflow" \
            -e AIRFLOW__DATABASE__SQL_ALCHEMY_CONN="postgresql+psycopg2://airflow:airflow@postgres/airflow" \
            -e AIRFLOW__CORE__EXECUTOR=LocalExecutor \
            -e AIRFLOW__CORE__LOAD_EXAMPLES=False \
            -v ${{ github.workspace }}/dags:/opt/airflow/dags \
            -v ${{ github.workspace }}/logs:/opt/airflow/logs \
            -v ${{ github.workspace }}/plugins:/opt/airflow/plugins \
            -v ${{ github.workspace }}/data:/opt/airflow/data \
            airflow_custom

      - name: Initialize Airflow DB
        run: |
          sleep 10  # Wait for services to be ready
          docker exec --user root airflow chmod -R 777 /opt/airflow/logs
          docker exec airflow airflow db init

      - name: Initialize Airflow
        run: |
          docker exec airflow airflow users create \
            --username admin \
            --password admin \
            --firstname Anonymous \
            --lastname Admin \
            --role Admin \
            --email admin@example.com

      - name: Create Airflow User
        run: |
          docker exec airflow airflow users create \
            --username admin \
            --password admin \
            --firstname Anonymous \
            --lastname Admin \
            --role Admin \
            --email admin@example.com

      - name: List and Trigger DAG
        run: |
          echo "Available DAGs:"
          docker exec airflow airflow dags list
          
          echo "Unpausing DAG:"
          docker exec airflow airflow dags unpause stock_prediction_pipeline
          
          echo "Triggering DAG:"
          docker exec airflow airflow dags trigger stock_prediction_pipeline
          
          echo "Waiting for DAG to complete..."
          sleep 60  # Adjust time based on your DAG's typical runtime

      - name: Wait for DAG to Generate Data
        run: |
          echo "Waiting for mitigated data to be generated..."
          for i in {1..30}; do
            if [ -f "data/mitigated/AAPL_mitigated.csv" ]; then
              echo "âœ“ AAPL data found"
              ls -l data/mitigated/AAPL_mitigated.csv
              break
            fi
            echo "Waiting... ($i/30)"
            sleep 10
          done

          # Verify data exists
          if [ ! -f "data/mitigated/AAPL_mitigated.csv" ]; then
            echo "Error: Mitigated data not generated"
            exit 1
          fi

      - name: Train Model
        run: |
          echo "Starting model training with mitigated data..."
          python -m models.train

      - name: Validate Model
        run: |
          echo "Starting model validation..."
          python -m models.validate
